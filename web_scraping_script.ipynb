{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping and analysis\n",
    "\n",
    "This Jupyter notebook includes some code to get you started with web scraping. We will use a package called `BeautifulSoup` to collect the data from the web. Once you've collected your data and saved it into a local `.csv` file you should start with your analysis.\n",
    "\n",
    "### Scraping data from Skytrax\n",
    "\n",
    "If you visit [https://www.airlinequality.com] you can see that there is a lot of data there. For this task, we are only interested in reviews related to British Airways and the Airline itself.\n",
    "\n",
    "If you navigate to this link: [https://www.airlinequality.com/airline-reviews/british-airways] you will see this data. Now, we can use `Python` and `BeautifulSoup` to collect all the links to the reviews and then to collect the text data on each of the individual review links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seat_type</th>\n",
       "      <th>is_verified</th>\n",
       "      <th>rating</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Economy Class</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-11-19</td>\n",
       "      <td>✅ Trip Verified |  4 Hours before takeoff we r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Economy Class</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-11-19</td>\n",
       "      <td>✅ Trip Verified |  I recently had a delay on B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business Class</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>2023-11-16</td>\n",
       "      <td>Not Verified |  Boarded on time, but it took a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Economy Class</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-11-16</td>\n",
       "      <td>✅ Trip Verified |  5 days before the flight, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Economy Class</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-11-14</td>\n",
       "      <td>Not Verified |  \\r\\nWe traveled to Lisbon for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        seat_type  is_verified rating date_posted  \\\n",
       "0   Economy Class         True      1  2023-11-19   \n",
       "1   Economy Class         True      3  2023-11-19   \n",
       "2  Business Class        False      8  2023-11-16   \n",
       "3   Economy Class         True      1  2023-11-16   \n",
       "4   Economy Class        False      1  2023-11-14   \n",
       "\n",
       "                                              review  \n",
       "0  ✅ Trip Verified |  4 Hours before takeoff we r...  \n",
       "1  ✅ Trip Verified |  I recently had a delay on B...  \n",
       "2  Not Verified |  Boarded on time, but it took a...  \n",
       "3  ✅ Trip Verified |  5 days before the flight, w...  \n",
       "4  Not Verified |  \\r\\nWe traveled to Lisbon for ...  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = pd.DataFrame(columns=['seat_type','is_verified', 'rating','date_posted','review'])\n",
    "\n",
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "pages = 38\n",
    "page_size = 100\n",
    "\n",
    "# for i in range(1, pages + 1):\n",
    "for i in range(1, pages + 1):\n",
    "\n",
    "    # print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "    for div in parsed_content.find_all('article', itemprop='review'):\n",
    "        \n",
    "        # review text\n",
    "        text_content = div.find('div', class_='text_content').get_text() \n",
    "        \n",
    "        # seat type\n",
    "        header_td = div.find('td', class_='review-rating-header cabin_flown')\n",
    "        if header_td:\n",
    "            value_td = header_td.find_next_sibling('td', class_='review-value')\n",
    "            if value_td:\n",
    "                review_value = value_td.text.strip()\n",
    "            else:\n",
    "                review_value = None\n",
    "        else:\n",
    "            review_value = None\n",
    "        \n",
    "        # checking if verified review \n",
    "        is_verified=True if \"Trip Verified\" in text_content else False\n",
    "        \n",
    "        # Overall rating by customer\n",
    "        if div.find('span', itemprop='ratingValue'):\n",
    "            overall_rating = div.find('span', itemprop='ratingValue').get_text()\n",
    "        else:\n",
    "            overall_rating = None\n",
    "        \n",
    "        # date review was posted\n",
    "        date_of_review = pd.to_datetime(div.find('time', itemprop=\"datePublished\").get_text())\n",
    "        \n",
    "        reviews_df.loc[len(reviews_df)] = {'seat_type':review_value, 'review': text_content, 'is_verified' : is_verified, 'rating': overall_rating, 'date_posted': date_of_review}\n",
    "        \n",
    "reviews_df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.to_csv(\"data/BA_reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Now you have your dataset for this task! The loops above collected 1000 reviews by iterating through the paginated pages on the website. However, if you want to collect more data, try increasing the number of pages!\n",
    "\n",
    " The next thing that you should do is clean this data to remove any unnecessary text from each of the rows. For example, \"✅ Trip Verified\" can be removed from each row if it exists, as it's not relevant to what we want to investigate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f7924c4c56b083e0e50eadfe7ef592a7a8ef70df33a0047f82280e6be1afe15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
